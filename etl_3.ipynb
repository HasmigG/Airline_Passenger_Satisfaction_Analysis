{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e10dd6db-38b3-45ce-873f-1a65e3af516c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import csv \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "07a28098-11ce-4f91-b833-02701a033486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Resources/airlines_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2697501e-772c-41c1-86a7-b28d8c429e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#some work on the columns #1\n",
    "\n",
    "def column_work(df):\n",
    "    \n",
    "    #create new db with only the needed columns\n",
    "    \n",
    "    df_new = df[['Title', 'Airline', 'Reviews',\n",
    "       'Type of Traveller', 'Month Flown', 'Route', 'Class', 'Seat Comfort',\n",
    "       'Staff Service', 'Food & Beverages', 'Inflight Entertainment',\n",
    "       'Value For Money', 'Overall Rating', 'Recommended']]\n",
    "    \n",
    "    #split the month flown column into two and make the month into a number\n",
    "        # first map the month names to their numbers\n",
    "\n",
    "    num_mon = {'January': 1, 'February': 2, 'March': 3, 'April': 4, 'May': 5, 'June': 6,\n",
    "                'July': 7, 'August': 8, 'September': 9, 'October': 10, 'November': 11, 'December': 12}\n",
    "\n",
    "    df_new['Year Flown'] = df_new['Month Flown'].str.split().str[1]\n",
    "    df_new['Month Flown'] = df_new['Month Flown'].str.split().str[0].map(num_mon)\n",
    "    #df_new.loc[:,'Year Flown'] = df_new[:'Month Flown'].str.split().str[1]\n",
    "    #df_new.loc[:, 'Month Flown'] = df_new.loc[:, 'Month Flown'].str.split().str[0].map(num_mon)\n",
    "\n",
    "    df_new.head()\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3eb1ce56-b8d0-4d81-86e5-9d81e9686ef6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/49dbrphx3bd0c4cm_7kpyb_m0000gn/T/ipykernel_4963/4156166323.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['Year Flown'] = df_new['Month Flown'].str.split().str[1]\n",
      "/var/folders/gw/49dbrphx3bd0c4cm_7kpyb_m0000gn/T/ipykernel_4963/4156166323.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new['Month Flown'] = df_new['Month Flown'].str.split().str[0].map(num_mon)\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "df_c = column_work(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "df426119-fe80-4d90-9ff7-36a015e3a344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the route column #2\n",
    "def split_to_via(df):\n",
    "    # Split the text based on separators (to, via)\n",
    "    split_values = df['Route'].str.split(r'(?<=\\bto\\b)|(?<=\\bvia\\b)', expand=True)\n",
    "    \n",
    "    # remove to and via from the split columns\n",
    "    split_values = split_values.apply(lambda x: x.str.replace(r'\\bto\\b|\\bvia\\b', '', regex=True))\n",
    "    \n",
    "    # Create new columns and load in the split values\n",
    "    df['Origin'] = split_values[0].str.strip()\n",
    "    df['Destination'] = split_values[1].str.strip()\n",
    "    \n",
    "    # Check if the 'Via' column exists and handle multiple cities\n",
    "    if 2 in split_values.columns:\n",
    "        df['Via'] = split_values[2].str.replace('/', '').str.split().str[0].str.strip()\n",
    "    else:\n",
    "        df['Via'] = ''\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ddb4990c-eed1-43c9-a628-197b65c3d78b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2\n",
    "df_d = split_to_via_2(df_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2d55ee55-2a29-49de-a5dd-6fddf3d2c1ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## text blobs #3\n",
    "def blob_function(df):\n",
    "\n",
    "    # extract the comments and ratings into a list\n",
    "\n",
    "    titles = df['Title'].to_list()\n",
    "    comments = df['Reviews'].to_list()\n",
    "\n",
    "    # create a blank list to hold the blob\n",
    "\n",
    "    polarities = []\n",
    "    subjectivities = []\n",
    "\n",
    "    # Analyze the sentiment of each comment \n",
    "\n",
    "    for comment in comments:\n",
    "      blob = TextBlob(comment)\n",
    "      polarity = blob.sentiment.polarity\n",
    "      subjectivity = blob.sentiment.subjectivity\n",
    "      polarities.append(polarity)\n",
    "      subjectivities.append(subjectivity)\n",
    "    \n",
    "     \n",
    "    # add values to new df columns\n",
    "\n",
    "    df['Comment Polarity'] = pd.Series(polarities)\n",
    "    df['Comment Subjectivity'] = pd.Series(subjectivities)\n",
    "\n",
    "    # erase lists to hold the blob\n",
    "\n",
    "    polarities = []\n",
    "    subjectivities = []    \n",
    "\n",
    "    # Analyze the sentiment of each title\n",
    "\n",
    "    for title in titles:\n",
    "      blob = TextBlob(title)\n",
    "      polarity = blob.sentiment.polarity\n",
    "      subjectivity = blob.sentiment.subjectivity\n",
    "      polarities.append(polarity)\n",
    "      subjectivities.append(subjectivity)\n",
    "\n",
    "     # add values to new df columns\n",
    "\n",
    "    df['Title Polarity'] = pd.Series(polarities)\n",
    "    df['Title Subjectivity'] = pd.Series(subjectivities)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "97f462bd-2297-4ebc-a78a-53278cee9135",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "df_e = blob_function(df_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7cd3f3a4-c9d9-4d97-8b7c-dae3e9a550b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# begin the one hot encoding #4\n",
    "\n",
    "def one_hot_e (df):\n",
    "    # get dummies \n",
    "    df = pd.get_dummies(df, columns = ['Class', 'Type of Traveller'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f1b143b7-55a0-4aae-ac5d-3613a9c44caa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4\n",
    "df_f = one_hot_e(df_e) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ab8d0219-bdda-4df2-ae6c-dcd956cedad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# more column work #5\n",
    "\n",
    "def col_work_dos(df):\n",
    "    #drop some columns\n",
    "    \n",
    "    df_renew = df[[ 'Airline', 'Month Flown', 'Year Flown', 'Seat Comfort',\n",
    "       'Staff Service', 'Food & Beverages', 'Inflight Entertainment',\n",
    "       'Value For Money', 'Overall Rating', 'Recommended', \n",
    "       'Origin', 'Destination', 'Via', 'Comment Polarity',\n",
    "       'Comment Subjectivity', 'Title Polarity', 'Title Subjectivity',\n",
    "       'Class_Business Class', 'Class_Economy Class', 'Class_First Class',\n",
    "       'Class_Premium Economy', 'Type of Traveller_Business',\n",
    "       'Type of Traveller_Couple Leisure', 'Type of Traveller_Family Leisure',\n",
    "       'Type of Traveller_Solo Leisure']]\n",
    "    \n",
    "    \n",
    "    # reformat recommended column values\n",
    "    df_renew ['Recommended'] = df_renew['Recommended'].replace({'no':0, 'yes':1})\n",
    "\n",
    "    return df_renew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ea9adbfd-745e-472b-afe5-0d1bf6e4a32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gw/49dbrphx3bd0c4cm_7kpyb_m0000gn/T/ipykernel_4963/1618135757.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_renew ['Recommended'] = df_renew['Recommended'].replace({'no':0, 'yes':1})\n",
      "/var/folders/gw/49dbrphx3bd0c4cm_7kpyb_m0000gn/T/ipykernel_4963/1618135757.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_renew ['Recommended'] = df_renew['Recommended'].replace({'no':0, 'yes':1})\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "df_g = col_work_dos(df_f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b6706-595b-4a64-8965-3747d9be1297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ed25cb-9aa6-457b-91d4-070cf4d1560d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def machine_fun(df):\n",
    "    #begin the machine\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = .2, random_state = 43)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4eccfc-c824-498e-9d8c-578ac4d5105d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
